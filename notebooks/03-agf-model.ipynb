{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambev data challenge\n",
    "## Adriano Freitas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de previsão de cumprimento da meta\n",
    "\n",
    "Este notebook tem o objetivo de criar um modelo para prever o cumprimento da meta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%run ./00-agf-utils.ipynb\n",
    "\n",
    "%store -r default_color\n",
    "%store -r default_light_color\n",
    "%store -r default_dark_color\n",
    "%store -r colormap\n",
    "%store -r figsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/processed/'\n",
    "file_name = 'ambev-final-dataset-processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_path, file_name))\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição do target\n",
    "Baseado no entendimento do dataset, temos 3 tipos de variáveis que retratam o atingimento das metas, são eles:\n",
    "- **Atingido (ating)**: Qual é o percentual da meta atingido no mês.\n",
    "- **Pontos (pontos)**: Os pontos são calculados baseado na regra de atingimento parcial (coluna `nom_regra_alcance_parcial`). Este valor é utilizado para calcular o atingimento final da meta.\n",
    "- **Acumulativo (acum)**: Mostra de forma acumulativa decompondo a meta pelo peso do KPI. Esta coluna é calculada aplicando o peso do kpi sobre os pontos.\n",
    "\n",
    "Decidimos então prever o percentual da meta que o funcionário vai atingir no mês, uma vez que essa é a medida raiz, sendo as outras colunas calculadas derivadas dessa. Com essa previsão poderemos calcular as demais e chegar na previsão do final do exercício."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição do modelo\n",
    "\n",
    "Decidimos aplicar uma rede neural recorrente (RNN) com células LSTM (Long Short Term Memory), que possuem ótima performance em séries temporais como essa em questão.\n",
    "\n",
    "Definimos um intervalo de observação de 3 meses, o que nos dará uma visão de sazonalidade. Nos baseamos na duração de cada estação do ano. Como temos um número de observações diferente a cada mês, vamos usar a média de observações de cada mês multiplicado por 3 como intervalo.\n",
    "\n",
    "A média encontrada foi de 10621 registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo quantos registros tem em média por mês\n",
    "# essa será nossa janela uma vez que cada mês possui uma quantidade diferente\n",
    "# de registros, isso nos dará aproximadamente 3 meses de observações\n",
    "# para gerar um previsão\n",
    "df.groupby(by='ord_mes_referencia').count().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling e Encoding e filtrando as colunas\n",
    "\n",
    "Vamos utilizar apenas o funcnioário, o KPI e seu percentual de atingimento.\n",
    "Precisamos também remover o último mês que será usado para o teste final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('nom_\\w+')\n",
    "col_search = np.vectorize(lambda x, pattern=pattern: bool(pattern.search(x)))\n",
    "idx_filter = col_search(df.columns)\n",
    "nom_cols = df.columns[idx_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_last_month(df):\n",
    "    df = df[df['ord_mes_referencia']<12]\n",
    "    return df\n",
    "\n",
    "def select_cols(df):\n",
    "    df = df[['dis_nome_funcionario', 'nom_codigo_kpi', 'per_ating_mes']]\n",
    "    return df\n",
    "\n",
    "drop_cols = [\n",
    "    'ord_mes_referencia', \n",
    "    'nom_pais',\n",
    "    'dis_nome_kpi', \n",
    "    'per_peso_kpi', \n",
    "    'nom_prazo',\n",
    "    'nom_cargo',\n",
    "    'nom_banda',\n",
    "    'nom_area',\n",
    "    'nom_regra_alcance_parcial', \n",
    "    'bin_meta_projeto', \n",
    "    'per_pontos_mes',\n",
    "    'per_acum_mes', \n",
    "    'per_ating_acumulado',\n",
    "    'per_pontos_acumulado', \n",
    "    'per_acum_acumulado', \n",
    "    'per_ating_fim_exer',\n",
    "    'per_pontos_fim_exer', \n",
    "    'per_acum_fim_exer'\n",
    "]\n",
    "\n",
    "prep_df = Prep(df) \\\n",
    "    .apply_custom(remove_last_month) \\\n",
    "    .apply_custom(select_cols) \\\n",
    "    .encode(['nom_codigo_kpi']) \\\n",
    "    .scale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df.df.shape\n",
    "prep_df.df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando X e y\n",
    "Vamos utilizar uma biblioteca de processamento paralelo para preparar o dataset de treino, para isso precisaremos separar os registros previsores (últimos 3 meses) para cada registro do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = prep_df.df.values\n",
    "# X, y = [], []\n",
    "# i_len = 10621 * 3\n",
    "\n",
    "# for i in range (i_len, len(train_df)):\n",
    "#     X.append(train_df[i - i_len : i, :17])\n",
    "#     y.append(train_df[i, 17])\n",
    "    \n",
    "# X, y = np.array(X), np.array(y)\n",
    "# print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "import dask.array as da\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "client = Client(threads_per_worker=4, n_workers=cpu_count())\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = da.from_array(prep_df.df.values, chunks=1000)\n",
    "i_len = 10621 * 3\n",
    "\n",
    "X = np.array([train_df[:i_len, :2]])\n",
    "y = np.array([train_df[i_len, 2]])\n",
    "print('inicio')\n",
    "X = [delayed(np.append)(X, np.array([train_df[i - i_len : i, :2]]), axis=0) for i in range(i_len+1, len(train_df))]\n",
    "X = compute(X)\n",
    "print('fim X')\n",
    "y = [delayed(np.append)(y, np.array([train_df[i, 2]]), axis=0) for i in range(i_len+1, len(train_df))]\n",
    "y = compute(y)\n",
    "print('fim y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X.shape[1], 17)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units = 100, \n",
    "               return_sequences = True, \n",
    "               input_shape = input_shape))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(LSTM(units = 50))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))  # linear\n",
    "\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss='mean_squared_error', \n",
    "              metrics=['mean_absolute_error'])\n",
    "\n",
    "es = EarlyStopping(monitor='loss', min_delta=1e-10, patience=10, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=5, verbose=1)\n",
    "mcp = ModelCheckpoint(filepath='weights.{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                      monitor='loss', save_best_only=True, verbose=1)\n",
    "\n",
    "model.fit(X, y, epochs=100, batch_size=32, callbacks=[es, reduce_lr, mcp])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
